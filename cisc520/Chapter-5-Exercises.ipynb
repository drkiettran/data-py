{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe437f1",
   "metadata": {},
   "source": [
    "# Module 6 & 7 - Associations\n",
    "\n",
    "## Notes\n",
    "- Install these packages:\n",
    "\n",
    "    + `pip3 install mlxtend`\n",
    "    + `pip3 install openpyxl`\n",
    "\n",
    "- Training data set is from here: \n",
    "    \n",
    "    + `https://archive.ics.uci.edu/ml/datasets/online+retail`  \n",
    "    + `http://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx`\n",
    "\n",
    "- Code example is from here: \n",
    "    + `https://pbpython.com/market-basket-analysis.html`\n",
    "    \n",
    "- Support & Confidence:\n",
    "\n",
    "    Support, $s(X \\to Y) = \\frac{\\sigma(X \\cup Y)}{N}$\n",
    "    \n",
    "    Confidence, $c(X \\to Y) = \\frac{\\sigma(X \\cup Y)}{\\sigma (X)}$\n",
    "    \n",
    "    Where, $X \\cap Y = \\emptyset $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced5a254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "from itertools import permutations, combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576d872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/Online_Retail.xlsx')\n",
    "# df = pd.read_excel('http://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx')\n",
    "init_series = df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea5ff1",
   "metadata": {},
   "source": [
    "## Notes\n",
    "Remove items that lack invoice number (Null/NaN) or have letter `C` as `credit transactions`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbde4c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Description'] = df['Description'].str.strip()\n",
    "df.dropna(axis=0, subset=['InvoiceNo'], inplace=True)\n",
    "df['InvoiceNo'] = df['InvoiceNo'].astype('str')\n",
    "df = df[~df['InvoiceNo'].str.contains('C')]\n",
    "print('initial length:', len(init_series))\n",
    "print('    new length:', len(df))\n",
    "print(' items removed:', len(init_series)-len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54569f3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basket = (df[df['Country'] == \"France\"]\n",
    "          .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('InvoiceNo'))\n",
    "basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa38324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_units(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >= 1:\n",
    "        return 1\n",
    "\n",
    "basket_sets = basket.applymap(encode_units)\n",
    "basket_sets.drop('POSTAGE', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6411aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = apriori(basket_sets, min_support=0.07, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6123d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "rules.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703fb8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101b9bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rules = rules[ (rules['lift'] >= 6) &\n",
    "       (rules['confidence'] >= 0.8) ]\n",
    "new_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb39ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8108058",
   "metadata": {},
   "outputs": [],
   "source": [
    "basket['ALARM CLOCK BAKELIKE GREEN'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d045d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "basket['ALARM CLOCK BAKELIKE RED'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ce46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "basket2 = (df[df['Country'] ==\"Germany\"]\n",
    "          .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('InvoiceNo'))\n",
    "\n",
    "basket_sets2 = basket2.applymap(encode_units)\n",
    "basket_sets2.drop('POSTAGE', inplace=True, axis=1)\n",
    "frequent_itemsets2 = apriori(basket_sets2, min_support=0.05, use_colnames=True)\n",
    "rules2 = association_rules(frequent_itemsets2, metric=\"lift\", min_threshold=1)\n",
    "\n",
    "rules2[ (rules2['lift'] >= 4) &\n",
    "        (rules2['confidence'] >= 0.5)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577c8d01",
   "metadata": {},
   "source": [
    "# Example #2\n",
    "\n",
    "`https://medium.com/analytics-vidhya/association-analysis-in-python-2b955d0180c`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00cced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('../data/retail_dataset.csv')\n",
    "dataset = df.to_numpy()\n",
    "df = df.replace(np.nan, '', regex=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351503db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = df.to_numpy()\n",
    "\n",
    "\n",
    "new_dataset = []\n",
    "for row in dataset:\n",
    "    new_row = []\n",
    "    for i in row:\n",
    "        if i != '':\n",
    "            new_row.append(i)\n",
    "    new_dataset.append(new_row)\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(new_dataset).transform(new_dataset)\n",
    "df1 = pd.DataFrame(te_ary, columns=te.columns_)    \n",
    "df1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf06bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569885a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_items = apriori(df1, min_support=0.25, use_colnames=True, verbose=1)\n",
    "freq_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15480f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.6)\n",
    "rules.head()\n",
    "print(len(rules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e9cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(rules['support'], rules['confidence'], alpha=0.5)\n",
    "plt.xlabel('support')\n",
    "plt.ylabel('confidence')\n",
    "plt.title('Support vs Confidence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf516a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(rules['support'], rules['lift'], alpha=0.5)\n",
    "plt.xlabel('support')\n",
    "plt.ylabel('lift')\n",
    "plt.title('Support vs Lift')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a598395",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = np.polyfit(rules['lift'], rules['confidence'], 1)\n",
    "plt.xlabel('lift')\n",
    "plt.ylabel('confidence')\n",
    "fit_fn = np.poly1d(fit)\n",
    "plt.plot(rules['lift'], rules['confidence'], 'yo', rules['lift'], fit_fn(rules['lift']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda9864",
   "metadata": {},
   "source": [
    "# Homework Assignment # 3\n",
    "\n",
    "1. Run the entire code below with these two datasets:\n",
    "\n",
    "```python\n",
    "T = [['a','b'], ['c','d'], ['a','c'], ['a','b','d'], ['a','e'], ['d'], ['a'], ['b']]\n",
    "T = [['Bread', 'Milk'], \n",
    "     ['Bread', 'Diapers', 'Beer', 'Eggs'], \n",
    "     ['Milk', 'Diapers', 'Beer', 'Cola'],\n",
    "     ['Bread', 'Milk', 'Diapers', 'Beer'],\n",
    "     ['Bread', 'Milk', 'Diapers', 'Cola']]\n",
    "\n",
    "```\n",
    "2. Don't run the congressional vote dataset. It is too large (36 variables)\n",
    "\n",
    "3. Verify the results of the program manually using the algorithms provided. \n",
    "\n",
    "4. Write your report and submit. Use either Jupyter notebook or Word or both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71527feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = ['','handicapped-infants','water-project-cost-sharing',\n",
    "          'adoption-of-the-budget-resolution',\n",
    "          'physician-fee-freeze',\n",
    "          'el-salvador-aid',\n",
    "          'religious-groups-in-schools',\n",
    "          'anti-satellite-test-ban',\n",
    "          'aid-to-nicaraguan-contras',\n",
    "          'mx-missile',\n",
    "          'immigration',\n",
    "          'synfuels-corporation-cutback',\n",
    "          'education-spending',\n",
    "          'superfund-right-to-sue',\n",
    "          'crime',\n",
    "          'duty-free-exports',\n",
    "          'export-administration-act-south-africa']\n",
    "len(issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88061db5",
   "metadata": {},
   "source": [
    "## Loading congressional votes 1984."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28262d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/house-votes-84.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04624ba",
   "metadata": {},
   "source": [
    "## Making Transaction set from a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bf6a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_T_from_dataframe(df):\n",
    "    new_T = []\n",
    "    for index, row in df.iterrows():\n",
    "        t = []\n",
    "        for item in row:\n",
    "            if len(item) > 0:\n",
    "                t.append(item)\n",
    "        new_T.append(t)\n",
    "    return new_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665b92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_84_congressional_votes(df):\n",
    "    new_T = []\n",
    "    for index, row in df.iterrows():\n",
    "        t = []\n",
    "        j = 0\n",
    "        for item in row:\n",
    "            if item == 'y' or item == 'n':\n",
    "                # t.append(issues[j]+'--'+item)\n",
    "                t.append(f'{j}_{item}')\n",
    "            elif item != '?':\n",
    "                t.append(item)\n",
    "            j += 1\n",
    "        new_T.append(t)\n",
    "    return new_T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae94953e",
   "metadata": {},
   "source": [
    "## Loading a Transaction sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08afe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = [['a','b'], ['c','d'], ['a','c'], ['a','b','d'], ['a','e'], ['d'], ['a'], ['b']]\n",
    "T = [['Bread', 'Milk'], \n",
    "     ['Bread', 'Diapers', 'Beer', 'Eggs'], \n",
    "     ['Milk', 'Diapers', 'Beer', 'Cola'],\n",
    "     ['Bread', 'Milk', 'Diapers', 'Beer'],\n",
    "     ['Bread', 'Milk', 'Diapers', 'Cola']]\n",
    "\n",
    "# df is loading elsewhere above\n",
    "# T = make_T_from_dataframe(df) \n",
    "\n",
    "# T = get_84_congressional_votes(df)\n",
    "\n",
    "sorted_T = []\n",
    "for t in T:\n",
    "    t.sort()\n",
    "    sorted_T.append(t)\n",
    "T = sorted_T    \n",
    "list(T)\n",
    "print(f'There are {len(T)} transactions:')\n",
    "display(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f345270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Universe set U from transaction set T\n",
    "def make_U(T):    \n",
    "    u = {}\n",
    "    for t in T:\n",
    "        for i in t:\n",
    "            u[i] = i\n",
    "    \n",
    "    U = list(u)\n",
    "    U.sort()\n",
    "    return U\n",
    "\n",
    "U = make_U(T)\n",
    "\n",
    "print(f'There are {len(U)} items:')\n",
    "display(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e9655a",
   "metadata": {},
   "source": [
    "# Brute-force\n",
    "Printing out a lattice of n items of universe U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261a46bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate all possible k-itemsets for a universe U\n",
    "Organize the list by row, with row 0 contains null,\n",
    "row 1 contains all 1-itemsets, row 2 contains all 2-itemsets, etc.\n",
    "\"\"\"\n",
    "def bf_all_itemsets(U):\n",
    "    bf_candidates = [[]]\n",
    "    print(U)\n",
    "    for c_len in range(1,len(U)+1):\n",
    "        cs = combinations(U,c_len)\n",
    "        row = []\n",
    "        for c in cs:\n",
    "            c = list(c)\n",
    "            c.sort()\n",
    "            row.append(c)\n",
    "\n",
    "        bf_candidates.append(row)\n",
    "    return bf_candidates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df1abeb",
   "metadata": {},
   "source": [
    "## Check to see if an item is in an itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c805b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "return whether or not a k_itemset is in a transaction t.\n",
    "\"\"\"\n",
    "def is_k_itemset_in_transaction(k_itemset, t):\n",
    "    return all(item in t for item in k_itemset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abde39f",
   "metadata": {},
   "source": [
    "## Get all the FI candidates that meet or exceed the support count based on a set of transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca1728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For a given set of k-itemsets, with at support count against a transaction T,\n",
    "return a set of frequent k-itemsets.\n",
    "\"\"\"\n",
    "\n",
    "def get_candidates(sup_count, k_itemsets, T):\n",
    "    k_itemset_coll = {}\n",
    "    \n",
    "    \"\"\"\n",
    "    First, we count the occurence of a k-itemset in the set of \n",
    "    transaction T.\n",
    "    \"\"\"\n",
    "    for k_itemset in k_itemsets:\n",
    "        k_itemset_key = '_'.join(k_itemset)\n",
    "        for t in T:\n",
    "            if is_k_itemset_in_transaction(k_itemset, t):\n",
    "                if k_itemset_key in k_itemset_coll:\n",
    "                    item = k_itemset_coll[k_itemset_key]\n",
    "                    item[1] += 1\n",
    "                    k_itemset_coll[k_itemset_key] = item\n",
    "                else:\n",
    "                    item = [k_itemset, 1]\n",
    "                    k_itemset_coll[k_itemset_key] = item           \n",
    "\n",
    "    \"\"\"\n",
    "    Then, we are looking for k-itemsets that is infrequent.\n",
    "    We keep the keys of the removal k-itemsets in a list\n",
    "    We then go through the removal list and remove the \n",
    "    k-itemsets by key\n",
    "    \"\"\"                \n",
    "    remove_keys = []\n",
    "    for i in k_itemset_coll:\n",
    "        item = k_itemset_coll[i]\n",
    "        if item[1] < sup_count:\n",
    "            remove_keys.append(i)\n",
    "    for key in remove_keys:\n",
    "        del k_itemset_coll[key]\n",
    "        \n",
    "    return k_itemset_coll\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941fa0db",
   "metadata": {},
   "source": [
    "## Displaying all itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f95313",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_itemsets = bf_all_itemsets(U)\n",
    "# display(all_itemsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb47a10",
   "metadata": {},
   "source": [
    "### Displaying the candidates and support count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfa2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sup_count in range(1, len(T)+1):\n",
    "    \n",
    "    minsup = sup_count/len(T)\n",
    "    print(f'\\n*** supp_count:{sup_count}, minsup:{minsup}\\n')\n",
    "\n",
    "    candidates = [[]] # Null first entry as in lattice      \n",
    "\n",
    "    for i in range(1,len(all_itemsets)):\n",
    "        candidates.append(get_candidates(sup_count, all_itemsets[i], T))\n",
    "\n",
    "    for i in range(1,len(candidates)):\n",
    "        print(f'{i}({len(candidates[i])}): {candidates[i]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfae2dc",
   "metadata": {},
   "source": [
    "# Apriori algorithm\n",
    "Implement Apriori algorithm ...\n",
    "\n",
    "$F_{k} = {i\\ |\\ i \\in I \\land \\sigma({i}) \\ge N \\ x \\ minsup}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460af983",
   "metadata": {},
   "source": [
    "## Step 1: Generating `k` itemsets from Universal U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e7d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generating a set of all possible k-itemsets transactions T \n",
    "from a set of universal items U\n",
    "\"\"\"\n",
    "def make_T(a_U, k):\n",
    "    cs = combinations(a_U, k)\n",
    "    k_itemsets = []\n",
    "    for c in cs:\n",
    "        c = list(c)\n",
    "        c.sort()\n",
    "        k_itemsets.append(c)\n",
    "    return k_itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc35f630",
   "metadata": {},
   "source": [
    "### Extract items out of a collection of k-itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf18685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_itemsets(ck):\n",
    "    k_itemsets = []\n",
    "    for item in ck:\n",
    "        k_itemsets.append(ck[item][0])\n",
    "    return k_itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34db8f61",
   "metadata": {},
   "source": [
    "### Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e478de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pruning. starting with 2. If k-1 subset of k_candidate \n",
    "is not a part of k_minus_1_candidate, drop the k-itemset.\n",
    "\"\"\"\n",
    "def candidate_prune(kminus1_candidates, k_candidates):\n",
    "    print('(k-1)-itemsets:')\n",
    "    display(kminus1_candidates)\n",
    "    print('k-itemsets:')\n",
    "    display(k_candidates)\n",
    "    \n",
    "    return_k_candidates = []\n",
    "    \n",
    "    for i in range(len(k_candidates)):        \n",
    "        k = len(k_candidates[i])        \n",
    "        if k == 1:\n",
    "            print('*** Nothing to prune ***')\n",
    "            return k_candidates\n",
    "            \n",
    "        k_candidate = [k_candidates[i]]\n",
    "        a_U = make_U(k_candidate)\n",
    "        kminus1_subsets = make_T(a_U, k-1)\n",
    "        if all(item in kminus1_candidates for item in kminus1_subsets):\n",
    "            return_k_candidates.append(k_candidates[i])\n",
    "            \n",
    "    return return_k_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b557ac1",
   "metadata": {},
   "source": [
    "### Generating Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc65b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generating all possible k-itemset transactions T\n",
    "from a previous set of (k-1)-itemsets \n",
    "\"\"\"\n",
    "def candidate_gen(kminus1_itemsets, k):  \n",
    "    return make_T(make_U(kminus1_itemsets), k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92015c4",
   "metadata": {},
   "source": [
    "### The apriori algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185c8202",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"    \n",
    "def apriori_gen(U, T, sup_count):    \n",
    "    UFk = [[]]\n",
    "    a_U = U\n",
    "    # display(a_U)\n",
    "    a_T = make_T(a_U, 1)\n",
    "    # display(a_T)\n",
    "\n",
    "    prev_ck = a_T\n",
    "    for k in range (1, 6):\n",
    "        print(f'*** generating {k}-itemsets ***')\n",
    "        #k_itemsets = make_T(a_U, k)\n",
    "        k_itemsets = candidate_gen(prev_ck, k)\n",
    "        \n",
    "        print(f'*** pruning {k}-itemsets ***')\n",
    "        # print('** before pruning **')\n",
    "        # display(k_itemsets)\n",
    "        k_itemsets = candidate_prune(prev_ck, k_itemsets)        \n",
    "        # print('** after pruning **')\n",
    "        # display(k_itemsets)\n",
    "\n",
    "        print('*** verifying frequent itemsets ***')\n",
    "        ck = get_candidates(sup_count, k_itemsets, T)\n",
    "        display(ck)\n",
    "        # k_itemsets = get_k_itemsets(ck)\n",
    "        prev_ck = get_k_itemsets(ck)\n",
    "\n",
    "        if ck == None or len(ck) == 0:\n",
    "            print ('** DONE **')\n",
    "            break\n",
    "\n",
    "        UFk.append(ck)\n",
    "        k_itemsets = get_k_itemsets(ck)\n",
    "        # a_U = make_U(k_itemsets)     \n",
    "    return UFk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022fa4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_count = 2\n",
    "UFk = apriori_gen(U, T, sup_count)\n",
    "\n",
    "print('*** UFk ***')\n",
    "display(UFk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6f5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Confidence\n",
    "# for each frequent k-itemset fk, k >= 2 do\n",
    "#   H1 = 1\n",
    "# end for\n",
    "\n",
    "for k in range(1, len(UFk)):\n",
    "    for key in UFk[k]:\n",
    "        k_itemset = UFk[k][key][0]\n",
    "        k_count = UFk[k][key][1]\n",
    "        print(key, k_itemset, k_count)\n",
    "        h1 = []\n",
    "        for item in k_itemset:\n",
    "            h1.append([item])\n",
    "        print(h1)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbbe228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# itemset = ['a','b','c']\n",
    "all_rules = {}\n",
    "for k in range(2, len(UFk)):\n",
    "    for key in UFk[k]:\n",
    "        k_itemset = UFk[k][key][0]\n",
    "        k_count = UFk[k][key][1]\n",
    "        print('\\n\\n***', key, k_itemset, k_count)\n",
    "        h1 = []\n",
    "\n",
    "        super_set = []\n",
    "        for count in range(1,len(k_itemset)):\n",
    "            for c in combinations(k_itemset, count):\n",
    "                value_key = '_'.join(c)\n",
    "                print(key, value_key, c, UFk[len(c)][value_key][1])\n",
    "                super_set.append(c)\n",
    "        \n",
    "        sig_a_b = k_count\n",
    "        rules \n",
    "        for i in range(len(super_set)-1):\n",
    "            a = super_set[i]\n",
    "            for j in range(i+1, len(super_set)):\n",
    "                b = super_set[j]\n",
    "                if set(a).isdisjoint(b) and len(a) + len(b) == len(k_itemset):\n",
    "                    sig_a = UFk[len(a)]['_'.join(a)][1]\n",
    "                    sig_b = UFk[len(b)]['_'.join(b)][1]                                        \n",
    "                    all_rules['_'.join(a) + '->' + '_'.join(b)] = sig_a_b/sig_a\n",
    "                    all_rules['_'.join(b) + '->' + '_'.join(a)] = sig_a_b/sig_b\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fb7519",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'there are {len(all_rules)} rules')\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88870ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'number of transaction in the dataset is {len(T)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421ff75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 0.97\n",
    "adopted_rules = {}\n",
    "for key in all_rules:\n",
    "    if all_rules[key] >= confidence:\n",
    "        adopted_rules[key] = all_rules[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bb67fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'there are {len(adopted_rules)} adopted rules of a {confidence} of confidence or greater')\n",
    "\n",
    "for key in adopted_rules:\n",
    "    if key.startswith('adoption-of-the-budget-resolution_mx-missile') and key.endswith('->democrat'):\n",
    "        print(key, adopted_rules[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22efe60",
   "metadata": {},
   "source": [
    "## Congressional Voting Record examples\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
